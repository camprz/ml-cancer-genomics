{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1204bbd-299f-4ab1-86e3-614a7078391d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependency management\n",
    "# --------------------------------------------------------\n",
    "import sys\n",
    "from pathlib import Path\n",
    "project_root = Path(\"..\").resolve()\n",
    "sys.path.append(str(project_root / \"scripts\"))\n",
    "from setup_environment import setup_paths\n",
    "project_root = setup_paths()\n",
    "\n",
    "# Data manipulation\n",
    "# --------------------------------------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import math\n",
    "import time\n",
    "import joblib\n",
    "\n",
    "# Visualizations\n",
    "# --------------------------------------------------------\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import missingno as msno\n",
    "import altair as alt\n",
    "from plotnine import ggplot, geom_point, aes, stat_smooth, facet_wrap\n",
    "from bokeh.plotting import figure, show\n",
    "import seaborn.objects as so\n",
    "import plotly.express as px\n",
    "\n",
    "# Custom scripts\n",
    "# ---------------------------------------------------------\n",
    "from data_processing.cleaner import (cleaning, \n",
    "                                     compare_and_drop_duplicates)\n",
    "from feature_selection.selector import (select_vars, \n",
    "                                       choose_variable_to_drop, \n",
    "                                       corr_comparison, \n",
    "                                       mutual_information)\n",
    "\n",
    "# Correlation\n",
    "# ---------------------------------------------------------\n",
    "from dython.nominal import associations\n",
    "\n",
    "# Dimension Reduction\n",
    "# ---------------------------------------------------------\n",
    "import umap\n",
    "\n",
    "# Preprocessing\n",
    "# ---------------------------------------------------------\n",
    "from sklearn.preprocessing import (MinMaxScaler, \n",
    "                                   RobustScaler, \n",
    "                                   QuantileTransformer, \n",
    "                                   OrdinalEncoder,\n",
    "                                  LabelEncoder)\n",
    "from sklearn import preprocessing\n",
    "from category_encoders import BinaryEncoder\n",
    "\n",
    "# Random Forest\n",
    "# ---------------------------------------------------------\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Support Vector Machine Classifier\n",
    "# ---------------------------------------------------------\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# XGBoost\n",
    "# ---------------------------------------------------------\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Model selection\n",
    "# ---------------------------------------------------------\n",
    "from sklearn.model_selection import (train_test_split, \n",
    "                                     RepeatedStratifiedKFold, \n",
    "                                     StratifiedKFold, \n",
    "                                     cross_val_score)\n",
    "\n",
    "# Metrics\n",
    "# ---------------------------------------------------------\n",
    "from sklearn.metrics import (accuracy_score, \n",
    "                             f1_score, \n",
    "                             precision_score, \n",
    "                             recall_score, \n",
    "                             confusion_matrix,\n",
    "                             make_scorer,\n",
    "                             classification_report,\n",
    "                             ConfusionMatrixDisplay\n",
    "                             )\n",
    "\n",
    "# Hyperparameter optimization\n",
    "# ----------------------------------------------------------\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "\n",
    "# GNN\n",
    "# ---------------------------------------------------------\n",
    "import torch\n",
    "from torch_geometric.data import HeteroData\n",
    "\n",
    "\n",
    "# Other\n",
    "# ---------------------------------------------------------\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "random.seed(2024)\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14c8e248-da3e-4e67-9e9f-dce7aab4ee34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(328116, 31)\n",
      "\n",
      "Index(['#chrom', 'chromStart', 'chromEnd', 'name', 'score', 'reserved',\n",
      "       'blockSizes', 'clinSign', 'reviewStatus', 'type', 'molConseq',\n",
      "       'testedInGtr', 'phenotypeList', 'origin', 'cytogenetic', 'vcfDesc',\n",
      "       '_clinSignCode', 'simplified_hgvs', 'Gene', 'ClinClass',\n",
      "       'Classification', 'bin_class', 'classification_oncokb', 'gen',\n",
      "       'gen_label', 'string_per_umap_cluster',\n",
      "       'string_per_umap_cluster_description', 'string_total_clustering',\n",
      "       'string_total_clustering_description', 'x_position', 'y_position'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Load saved merged_df.csv\n",
    "merged_df = pd.read_csv(f\"{project_root}/data/interim/merged_df.csv\")\n",
    "print(merged_df.shape)\n",
    "print()\n",
    "print(merged_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adaceb7f-04e1-42c7-bbbc-bfcab2403214",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['#chrom', 'name', 'score', 'blockSizes', 'reviewStatus', 'type',\n",
       "       'molConseq', 'phenotypeList', 'origin', 'cytogenetic',\n",
       "       'simplified_hgvs', 'Gene', 'bin_class', 'classification_oncokb',\n",
       "       'gen_label', 'string_per_umap_cluster_description',\n",
       "       'string_total_clustering_description', 'x_position', 'y_position'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Final columns to drop\n",
    "final_drop_check = [\"geneId\", \"_originCode\", \"_allTypeCode\", \"ClinInfo\", \n",
    "                     \"reserved\", \"numSubmit\", \"_variantId\", \"real_id\", \n",
    "                     \"origName\", \"rcvAcc\", \"snpId\", \"Start\", \"End\", \"phenotype\", \n",
    "                    \"_mouseOver\", \"Classification\", \"_clinSignCode\", \n",
    "                    'clinSign', \"ClinClass\", \"chromStart\", \"chromEnd\", \"gen\", \n",
    "                    \"vcfDesc\", \"testedInGtr\", \"string_per_umap_cluster\", \"string_total_clustering\"]\n",
    "\n",
    "for i in final_drop_check:\n",
    "    if i in merged_df.columns:\n",
    "        merged_df = merged_df.drop([i], axis=1)\n",
    "\n",
    "merged_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b581e36d-32df-4548-bfaa-d7cd6bfa97a8",
   "metadata": {},
   "source": [
    "# Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e50c0b42-ef37-448c-b19e-85fd1d1dd741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([{'name': 'aip',\n",
       "   'gen_label': 9,\n",
       "   'x_position': 0.2159479553903345,\n",
       "   'y_position': 0.3324501032346869,\n",
       "   'clustering_description': 'DNA repair pathways, full network, and HDR through Homologous Recombination (HRR) '},\n",
       "  {'name': 'akt1',\n",
       "   'gen_label': 9,\n",
       "   'x_position': 0.4588475836431226,\n",
       "   'y_position': 0.4470406056434962,\n",
       "   'clustering_description': 'DNA repair pathways, full network, and HDR through Homologous Recombination (HRR) '},\n",
       "  {'name': 'alk',\n",
       "   'gen_label': 18,\n",
       "   'x_position': 0.4642007434944238,\n",
       "   'y_position': 0.5541982105987613,\n",
       "   'clustering_description': 'DNA repair pathways, full network, and HDR through Homologous Recombination (HRR) '},\n",
       "  {'name': 'antxr1',\n",
       "   'gen_label': 5,\n",
       "   'x_position': 0.6950557620817844,\n",
       "   'y_position': 0.7784239504473504,\n",
       "   'clustering_description': 'Uptake and function of anthrax toxins Mixed, incl. Anthrax disease, and SH3-binding 5'},\n",
       "  {'name': 'antxr2',\n",
       "   'gen_label': 12,\n",
       "   'x_position': 0.7566171003717472,\n",
       "   'y_position': 0.8477976600137647,\n",
       "   'clustering_description': 'Uptake and function of anthrax toxins Mixed, incl. Anthrax disease, and SH3-binding 5'}],\n",
       " [{'gene': 'aip',\n",
       "   'type': 'single nucleotide variant',\n",
       "   'molConseq': '5 prime utr variant',\n",
       "   'blockSizes': 1,\n",
       "   'score': 1,\n",
       "   'reviewStatus': 'criteria_provided_no_conflict',\n",
       "   'bin_class': 0},\n",
       "  {'gene': 'aip',\n",
       "   'type': 'single nucleotide variant',\n",
       "   'molConseq': '5 prime utr variant',\n",
       "   'blockSizes': 1,\n",
       "   'score': 1,\n",
       "   'reviewStatus': 'criteria_provided_no_conflict',\n",
       "   'bin_class': 0},\n",
       "  {'gene': 'aip',\n",
       "   'type': 'single nucleotide variant',\n",
       "   'molConseq': '5 prime utr variant',\n",
       "   'blockSizes': 1,\n",
       "   'score': 1,\n",
       "   'reviewStatus': 'criteria_provided_no_conflict',\n",
       "   'bin_class': 0},\n",
       "  {'gene': 'aip',\n",
       "   'type': 'single nucleotide variant',\n",
       "   'molConseq': '5 prime utr variant',\n",
       "   'blockSizes': 1,\n",
       "   'score': 1,\n",
       "   'reviewStatus': 'criteria_provided_no_conflict',\n",
       "   'bin_class': 0},\n",
       "  {'gene': 'aip',\n",
       "   'type': 'single nucleotide variant',\n",
       "   'molConseq': '5 prime utr variant',\n",
       "   'blockSizes': 1,\n",
       "   'score': 1,\n",
       "   'reviewStatus': 'criteria_provided_no_conflict',\n",
       "   'bin_class': 0}])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = merged_df.copy()\n",
    "\n",
    "# Step 1: Create Gene Nodes\n",
    "genes = data['Gene'].unique()  # Get unique genes\n",
    "\n",
    "gene_nodes = []\n",
    "for gene in genes:\n",
    "    gene_data = data[data['Gene'] == gene].iloc[0]  # Take the first occurrence of the gene to extract features\n",
    "    gene_node = {\n",
    "        'name': gene,\n",
    "        'gen_label': gene_data['gen_label'],  # Oncogenic or tumor suppressor label\n",
    "        'x_position': gene_data['x_position'],  # Latent space position X\n",
    "        'y_position': gene_data['y_position'],  # Latent space position Y\n",
    "        'clustering_description': gene_data['string_total_clustering_description']  # Clustering description\n",
    "    }\n",
    "    gene_nodes.append(gene_node)\n",
    "\n",
    "# Step 2: Create Variant Nodes\n",
    "variant_nodes = []\n",
    "for index, row in data.iterrows():\n",
    "    variant_node = {\n",
    "        'gene': row['Gene'],                    # Associated gene for the variant\n",
    "        'type': row['type'],                    # Variant type (e.g., deletion, duplication)\n",
    "        'molConseq': row['molConseq'],          # Molecular consequence (e.g., nonsense, frameshift)\n",
    "        'blockSizes': row['blockSizes'],        # Variant size or block size\n",
    "        'score': row['score'],                  # Score associated with the variant\n",
    "        'reviewStatus': row['reviewStatus'],    # Review status (e.g., reviewed, not classified)\n",
    "        'bin_class': row['bin_class']           # Binary classification (pathogenic or not)\n",
    "    }\n",
    "    variant_nodes.append(variant_node)\n",
    "\n",
    "# Output examples of the created nodes\n",
    "gene_nodes[:5], variant_nodes[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac7eb555-4e8a-4c0c-998b-0ef51612e728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gene_nodes 136\n",
      "variant_nodes 328116\n"
     ]
    }
   ],
   "source": [
    "print(\"gene_nodes\", len(gene_nodes))\n",
    "print(\"variant_nodes\", len(variant_nodes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567a5ddf-13fa-4685-9876-de2263d7a0fd",
   "metadata": {},
   "source": [
    "# Edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88a1fff1-d1ec-407e-a1f0-626cf91fe55d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([{'gene': 'aip',\n",
       "   'variant': 'single nucleotide variant',\n",
       "   'blockSizes': 1,\n",
       "   'cytogenetic_region': '11q13.2'},\n",
       "  {'gene': 'aip',\n",
       "   'variant': 'single nucleotide variant',\n",
       "   'blockSizes': 1,\n",
       "   'cytogenetic_region': '11q13.2'},\n",
       "  {'gene': 'aip',\n",
       "   'variant': 'single nucleotide variant',\n",
       "   'blockSizes': 1,\n",
       "   'cytogenetic_region': '11q13.2'},\n",
       "  {'gene': 'aip',\n",
       "   'variant': 'single nucleotide variant',\n",
       "   'blockSizes': 1,\n",
       "   'cytogenetic_region': '11q13.2'},\n",
       "  {'gene': 'aip',\n",
       "   'variant': 'single nucleotide variant',\n",
       "   'blockSizes': 1,\n",
       "   'cytogenetic_region': '11q13.2'}],\n",
       " [{'gene1': 'akt1', 'gene2': 'xrcc3', 'region': '14q32.33'},\n",
       "  {'gene1': 'ddb2', 'gene2': 'ext2', 'region': '11p11.2'},\n",
       "  {'gene1': 'epcam', 'gene2': 'msh2', 'region': '2p21'},\n",
       "  {'gene1': 'fanca', 'gene2': 'mc1r', 'region': '16q24.3'},\n",
       "  {'gene1': 'fancc', 'gene2': 'ptch1', 'region': '9q22.32'}])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 2: Create Gene-Variant Edges\n",
    "\n",
    "gene_variant_edges = []\n",
    "\n",
    "for index, row in data.iterrows():\n",
    "    gene = row['Gene']\n",
    "    variant_type = row['type']\n",
    "    \n",
    "    edge = {\n",
    "        'gene': gene,  # Source: Gene node\n",
    "        'variant': variant_type,  # Target: Variant node (use 'type' as the variant representation)\n",
    "        'blockSizes': row['blockSizes'],  # Optional edge weight\n",
    "        'cytogenetic_region': row['cytogenetic'],  # Cytogenetic region information\n",
    "    }\n",
    "    \n",
    "    gene_variant_edges.append(edge)\n",
    "\n",
    "# Optional Step: Create Gene-Gene Edges based on Cytogenetic region or Latent space proximity\n",
    "gene_gene_edges = []\n",
    "cytogenetic_regions = data['cytogenetic'].unique()\n",
    "\n",
    "for region in cytogenetic_regions:\n",
    "    # Find all genes in the same cytogenetic region\n",
    "    genes_in_region = data[data['cytogenetic'] == region]['Gene'].unique()\n",
    "    \n",
    "    # Create edges between all pairs of genes in this region\n",
    "    for i, gene1 in enumerate(genes_in_region):\n",
    "        for gene2 in genes_in_region[i + 1:]:\n",
    "            edge = {\n",
    "                'gene1': gene1,  # Source: Gene node 1\n",
    "                'gene2': gene2,  # Target: Gene node 2\n",
    "                'region': region,  # Cytogenetic region shared between both genes\n",
    "            }\n",
    "            gene_gene_edges.append(edge)\n",
    "\n",
    "# Output examples of created edges\n",
    "gene_variant_edges[:5], gene_gene_edges[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90243af3-0f0a-4731-87d2-c70e245a45d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gene_variant_edges 328116\n",
      "gene_gene_edges 20\n"
     ]
    }
   ],
   "source": [
    "print(\"gene_variant_edges\", len(gene_variant_edges))\n",
    "print(\"gene_gene_edges\", len(gene_gene_edges))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e6040f-fb39-4877-af53-d371d756946f",
   "metadata": {},
   "source": [
    "# Graph representation: Heterograph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b9c0bff-3b83-442a-ac69-19cb70256421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Graph Representation using PyTorch Geometric\n",
    "# Create HeteroData object\n",
    "data = HeteroData()\n",
    "\n",
    "# Add Gene nodes\n",
    "gene_x = []\n",
    "gene_labels = []\n",
    "for gene in gene_nodes:\n",
    "    gene_x.append([gene['x_position'], gene['y_position']])  # Latent positions as node features\n",
    "    gene_labels.append(gene['gen_label'])  # Gene label (oncogenic/tumor suppressor)\n",
    "\n",
    "data['gene'].x = torch.tensor(gene_x, dtype=torch.float)  # Node features for genes\n",
    "data['gene'].y = torch.tensor(gene_labels, dtype=torch.long)  # Labels for gene nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b9062bf-367d-42da-b615-b243ee2145d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Variant nodes\n",
    "variant_x = []\n",
    "variant_labels = []\n",
    "for variant in variant_nodes:\n",
    "    variant_x.append([variant['blockSizes']])  # Variant features (e.g., blockSizes)\n",
    "    variant_labels.append(variant['bin_class'])  # Pathogenicity label (binary classification)\n",
    "\n",
    "data['variant'].x = torch.tensor(variant_x, dtype=torch.float)  # Node features for variants\n",
    "data['variant'].y = torch.tensor(variant_labels, dtype=torch.long)  # Labels for variant nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29069e1b-18e2-4726-8b20-6a0073e13c05",
   "metadata": {},
   "source": [
    "# Optimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fbb25298-9883-4342-882d-0cb1b4046825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Optimized Graph Representation\n",
    "\n",
    "# Create mapping for gene names to their indices for faster lookups\n",
    "gene_idx_map = {gene['name']: idx for idx, gene in enumerate(gene_nodes)}\n",
    "\n",
    "# Create mapping for variant nodes based on gene name and variant type\n",
    "variant_idx_map = {(variant['gene'], variant['type']): idx for idx, variant in enumerate(variant_nodes)}\n",
    "\n",
    "# Create Gene-Variant edges using the pre-built index maps\n",
    "gene_to_variant_edge_index = [[], []]\n",
    "\n",
    "for edge in gene_variant_edges:\n",
    "    gene_idx = gene_idx_map.get(edge['gene'])\n",
    "    variant_idx = variant_idx_map.get((edge['gene'], edge['variant']))\n",
    "    \n",
    "    if gene_idx is not None and variant_idx is not None:\n",
    "        gene_to_variant_edge_index[0].append(gene_idx)\n",
    "        gene_to_variant_edge_index[1].append(variant_idx)\n",
    "\n",
    "# Convert edge index to tensor\n",
    "data['gene', 'interacts_with', 'variant'].edge_index = torch.tensor(gene_to_variant_edge_index, dtype=torch.long)\n",
    "\n",
    "# Optional: Optimize Gene-Gene edge creation similarly\n",
    "gene_to_gene_edge_index = [[], []]\n",
    "\n",
    "for edge in gene_gene_edges:\n",
    "    gene1_idx = gene_idx_map.get(edge['gene1'])\n",
    "    gene2_idx = gene_idx_map.get(edge['gene2'])\n",
    "    \n",
    "    if gene1_idx is not None and gene2_idx is not None:\n",
    "        # Add bidirectional edges\n",
    "        gene_to_gene_edge_index[0].append(gene1_idx)\n",
    "        gene_to_gene_edge_index[1].append(gene2_idx)\n",
    "        gene_to_gene_edge_index[0].append(gene2_idx)\n",
    "        gene_to_gene_edge_index[1].append(gene1_idx)\n",
    "\n",
    "# Convert edge index to tensor\n",
    "data['gene', 'connected_to', 'gene'].edge_index = torch.tensor(gene_to_gene_edge_index, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c828135-d2c1-46d6-a919-2c5dc9b5dcc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HeteroData(\n",
      "  gene={\n",
      "    x=[136, 2],\n",
      "    y=[136],\n",
      "  },\n",
      "  variant={\n",
      "    x=[328116, 1],\n",
      "    y=[328116],\n",
      "  },\n",
      "  (gene, interacts_with, variant)={ edge_index=[2, 328116] },\n",
      "  (gene, connected_to, gene)={ edge_index=[2, 40] }\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58fe74b-a4bd-4fd4-9d13-1f5bb972e8fe",
   "metadata": {},
   "source": [
    "```python\n",
    "HeteroData(\n",
    "  gene={\n",
    "    x=[136, 2],   # 136 genes, each with 2 features (x_position, y_position)\n",
    "    y=[136],      # 136 gene labels (e.g., oncogenic/tumor suppressor)\n",
    "  },\n",
    "  variant={\n",
    "    x=[328116, 1],  # 328,116 variants, each with 1 feature (e.g., blockSizes)\n",
    "    y=[328116],     # 328,116 binary labels (pathogenic or non-pathogenic)\n",
    "  },\n",
    "  (gene, interacts_with, variant)={ edge_index=[2, 328116] },   # 328,116 edges between genes and variants\n",
    "  (gene, connected_to, gene)={ edge_index=[2, 40] }  # 40 gene-gene connections (bidirectional edges)\n",
    ")\n",
    "\n",
    "\n",
    "gene_nodes 136\n",
    "variant_nodes 328116\n",
    "gene_variant_edges 328116\n",
    "gene_gene_edges 20\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed2a5534-82c0-4836-b94a-11ce2c85313a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['gene', 'variant'],\n",
       " [('gene', 'interacts_with', 'variant'), ('gene', 'connected_to', 'gene')])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.metadata()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46140f91-c8e8-41ce-8726-3bc3563c0dce",
   "metadata": {},
   "source": [
    "# Save HeteroData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d385fa8b-5008-4b4e-abfe-a93d50bfce3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to data/processed/hetero_graph.pt\n",
      "Data loaded from data/processed/hetero_graph.pt\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.data import HeteroData\n",
    "import torch\n",
    "import os\n",
    "\n",
    "# To save the data\n",
    "def save_hetero_data(data: HeteroData, path: str):\n",
    "    \"\"\"\n",
    "    Save a HeteroData object to disk.\n",
    "    \n",
    "    Args:\n",
    "        data (HeteroData): The heterogeneous graph data to save\n",
    "        path (str): Path where to save the data\n",
    "    \"\"\"\n",
    "    # Create directory if it doesn't exist\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "    \n",
    "    # Save the data\n",
    "    torch.save(data, path)\n",
    "    print(f\"Data saved to {path}\")\n",
    "\n",
    "# To load the data\n",
    "def load_hetero_data(path: str) -> HeteroData:\n",
    "    \"\"\"\n",
    "    Load a HeteroData object from disk.\n",
    "    \n",
    "    Args:\n",
    "        path (str): Path to the saved data file\n",
    "        \n",
    "    Returns:\n",
    "        HeteroData: The loaded heterogeneous graph data\n",
    "    \"\"\"\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(f\"No data file found at {path}\")\n",
    "    \n",
    "    data = torch.load(path)\n",
    "    print(f\"Data loaded from {path}\")\n",
    "    return data\n",
    "\n",
    "# Example usage:\n",
    "# Saving\n",
    "data_path = \"data/processed/hetero_graph.pt\"\n",
    "save_hetero_data(data, data_path)\n",
    "\n",
    "# Loading\n",
    "loaded_data = load_hetero_data(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defa2c80-ae6a-40d1-8f48-33dec543d77f",
   "metadata": {},
   "source": [
    "# GraphSAGE Multiheaded Attetion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acb8a08-0d03-449b-ab3f-234fcdad8a56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-25 20:54:55,788] A new study created in memory with name: no-name-0b0903be-4a64-4b70-be5f-cbadfc8d5fac\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of gene classes: 20\n",
      "Number of variant classes: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-25 20:57:11,289] Trial 0 finished with value: 0.24115569222129823 and parameters: {'hidden_channels': 64, 'out_channels': 96, 'num_layers': 3, 'num_heads': 2, 'learning_rate': 0.00031143723246377226, 'activation': 'leaky_relu'}. Best is trial 0 with value: 0.24115569222129823.\n",
      "[I 2024-10-25 20:59:01,821] Trial 1 finished with value: 0.2939507735858973 and parameters: {'hidden_channels': 32, 'out_channels': 96, 'num_layers': 2, 'num_heads': 4, 'learning_rate': 0.005981493620071629, 'activation': 'gelu'}. Best is trial 1 with value: 0.2939507735858973.\n",
      "[I 2024-10-25 21:05:08,553] Trial 2 finished with value: 0.24115569222129823 and parameters: {'hidden_channels': 64, 'out_channels': 128, 'num_layers': 4, 'num_heads': 4, 'learning_rate': 0.0006158007801911105, 'activation': 'leaky_relu'}. Best is trial 1 with value: 0.2939507735858973.\n",
      "[I 2024-10-25 21:06:03,472] Trial 3 finished with value: 0.24115569222129823 and parameters: {'hidden_channels': 32, 'out_channels': 96, 'num_layers': 3, 'num_heads': 1, 'learning_rate': 0.00022164069540887843, 'activation': 'leaky_relu'}. Best is trial 1 with value: 0.2939507735858973.\n",
      "[I 2024-10-25 21:10:22,322] Trial 4 finished with value: 0.2475753966514487 and parameters: {'hidden_channels': 128, 'out_channels': 128, 'num_layers': 2, 'num_heads': 4, 'learning_rate': 0.0010851861447637773, 'activation': 'leaky_relu'}. Best is trial 1 with value: 0.2939507735858973.\n",
      "[I 2024-10-25 21:12:05,376] Trial 5 finished with value: 0.23902479419998926 and parameters: {'hidden_channels': 32, 'out_channels': 96, 'num_layers': 3, 'num_heads': 3, 'learning_rate': 0.0007558244500982356, 'activation': 'leaky_relu'}. Best is trial 1 with value: 0.2939507735858973.\n",
      "[I 2024-10-25 21:14:35,307] Trial 6 finished with value: 0.24115569222129823 and parameters: {'hidden_channels': 64, 'out_channels': 128, 'num_layers': 3, 'num_heads': 2, 'learning_rate': 0.0001968872764373687, 'activation': 'leaky_relu'}. Best is trial 1 with value: 0.2939507735858973.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import SAGEConv, HeteroConv, Linear\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import HeteroConv, SAGEConv\n",
    "from torch.optim import Adam\n",
    "from torch.nn import Linear\n",
    "from sklearn.metrics import f1_score\n",
    "import optuna\n",
    "from optuna.trial import Trial\n",
    "from torch_geometric.data import HeteroData\n",
    "\n",
    "# Determine the number of classes for genes and variants\n",
    "num_gene_classes = len(torch.unique(data['gene'].y))\n",
    "num_variant_classes = len(torch.unique(data['variant'].y))\n",
    "\n",
    "print(f\"Number of gene classes: {num_gene_classes}\")\n",
    "print(f\"Number of variant classes: {num_variant_classes}\")\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, num_heads):\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.attentions = nn.ModuleList([\n",
    "            nn.Linear(in_channels, out_channels) for _ in range(num_heads)\n",
    "        ])\n",
    "        self.out_proj = nn.Linear(out_channels * num_heads, out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.cat([att(x) for att in self.attentions], dim=-1)\n",
    "        return self.out_proj(x)\n",
    "\n",
    "# Define the model class as provided\n",
    "class GraphSAGEWithAttention(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, out_channels, num_layers, num_heads, num_gene_classes, num_variant_classes, activation_fn):\n",
    "        super().__init__()\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.attentions = torch.nn.ModuleList()\n",
    "        self.activation_fn = activation_fn\n",
    "\n",
    "        # Initial convolution layer\n",
    "        self.convs.append(HeteroConv({\n",
    "            ('gene', 'interacts_with', 'variant'): SAGEConv((-1, -1), hidden_channels),\n",
    "            ('gene', 'connected_to', 'gene'): SAGEConv((-1, -1), hidden_channels),\n",
    "            ('variant', 'rev_interacts_with', 'gene'): SAGEConv((-1, -1), hidden_channels)\n",
    "        }))\n",
    "        self.attentions.append(MultiHeadAttention(hidden_channels, hidden_channels, num_heads))\n",
    "\n",
    "        # Hidden convolution layers\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.convs.append(HeteroConv({\n",
    "                ('gene', 'interacts_with', 'variant'): SAGEConv((-1, -1), hidden_channels),\n",
    "                ('gene', 'connected_to', 'gene'): SAGEConv((-1, -1), hidden_channels),\n",
    "                ('variant', 'rev_interacts_with', 'gene'): SAGEConv((-1, -1), hidden_channels)\n",
    "            }))\n",
    "            self.attentions.append(MultiHeadAttention(hidden_channels, hidden_channels, num_heads))\n",
    "\n",
    "        # Final convolution layer\n",
    "        self.convs.append(HeteroConv({\n",
    "            ('gene', 'interacts_with', 'variant'): SAGEConv((-1, -1), out_channels),\n",
    "            ('gene', 'connected_to', 'gene'): SAGEConv((-1, -1), out_channels),\n",
    "            ('variant', 'rev_interacts_with', 'gene'): SAGEConv((-1, -1), out_channels)\n",
    "        }))\n",
    "        self.attentions.append(MultiHeadAttention(out_channels, out_channels, num_heads))\n",
    "\n",
    "        self.gene_lin = Linear(out_channels, num_gene_classes)\n",
    "        self.variant_lin = Linear(out_channels, num_variant_classes)\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict):\n",
    "        for conv, attention in zip(self.convs, self.attentions):\n",
    "            x_dict = conv(x_dict, edge_index_dict)\n",
    "            x_dict = {key: attention(self.activation_fn(x)) for key, x in x_dict.items()}\n",
    "\n",
    "        return {\n",
    "            'gene': self.gene_lin(x_dict['gene']),\n",
    "            'variant': self.variant_lin(x_dict['variant'])\n",
    "        }\n",
    "\n",
    "\n",
    "#config = {\n",
    "#    \"hidden_channels\": tune.choice([64]),\n",
    "#    \"out_channels\": tune.choice([32, 64]),\n",
    "#    \"num_layers\": tune.choice([2, 3, 4, 5]),\n",
    "#    \"num_heads\": tune.choice([2, 4]),\n",
    "#    \"lr\": tune.loguniform(1e-4, 1e-2),\n",
    "#    \"weight_decay\": tune.loguniform(1e-5, 1e-3),\n",
    "#    \"dropout_rate\": tune.uniform(0.1, 0.5),\n",
    "#    \"activation_fn\": tune.choice([\"relu\", \"gelu\", \"leaky_relu\"]),\n",
    "#}\n",
    "    \n",
    "\n",
    "# Define the objective function for optuna\n",
    "def objective(trial: Trial, data: HeteroData):\n",
    "    # Set the device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # Hyperparameter search space\n",
    "    hidden_channels = trial.suggest_int(\"hidden_channels\", 32, 128, step=32)\n",
    "    out_channels = trial.suggest_int(\"out_channels\", 32, 128, step=32)\n",
    "    num_layers = trial.suggest_int(\"num_layers\", 2, 4)\n",
    "    num_heads = trial.suggest_int(\"num_heads\", 1, 4)\n",
    "    learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-4, 1e-2)\n",
    "    dropout_rate = trial.suggest_uniform(\"dropout\", 0.0, 0.5)  # Added dropout with a reasonable range\n",
    "    \n",
    "    # Choose activation function\n",
    "    activation_name = trial.suggest_categorical(\"activation\", [\"gelu\", \"leaky_relu\"])\n",
    "    activation_fn = F.gelu if activation_name == \"gelu\" else F.leaky_relu\n",
    "\n",
    "    # Initialize the model, optimizer, and loss function\n",
    "    model = GraphSAGEWithAttention(hidden_channels, out_channels, num_layers, num_heads, \n",
    "                                   num_gene_classes=num_gene_classes, \n",
    "                                   num_variant_classes=num_variant_classes,\n",
    "                                   activation_fn=activation_fn).to(device)\n",
    "    optimizer = Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Training loop\n",
    "    model.train()\n",
    "    for epoch in range(10):  # Short epochs for optimization speed\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data.x_dict, data.edge_index_dict)\n",
    "        loss = F.cross_entropy(out['gene'], data['gene'].y) + F.cross_entropy(out['variant'], data['variant'].y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Evaluation with F1 score on validation data\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        out = model(data.x_dict, data.edge_index_dict)\n",
    "        gene_pred = out['gene'].argmax(dim=1)\n",
    "        variant_pred = out['variant'].argmax(dim=1)\n",
    "\n",
    "        # Calculate F1 scores\n",
    "        gene_f1 = f1_score(data['gene'].y.cpu(), gene_pred.cpu(), average=\"macro\")\n",
    "        print(gene_f1)\n",
    "        variant_f1 = f1_score(data['variant'].y.cpu(), variant_pred.cpu(), average=\"macro\")\n",
    "        print(variant_f1)\n",
    "        f1 = (gene_f1 + variant_f1) / 2\n",
    "\n",
    "    return f1\n",
    "\n",
    "# Set up and execute the optuna study\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(lambda trial: objective(trial, data), n_trials=50)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best hyperparameters:\", study.best_params)\n",
    "print(\"Best F1 score:\", study.best_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31e192e-fc85-4e5e-8022-9b5b71b6a33a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c418094-84b3-4e3d-a06d-afcaa360f706",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65ea338-f2c6-42e7-85f2-fe1d5315c584",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87349721-cc8c-4611-ac41-06066b693498",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e811c1-6253-45cc-828a-6740fe06db68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa28db8-4da2-41a5-915b-39d860e14928",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "20e54aa2-e381-459e-85c2-f29d2790c0fe",
   "metadata": {},
   "source": [
    "# Embedding UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a235132e-0181-4767-8584-80fde3f9b9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "hidden_channels = 128\n",
    "out_channels = 64\n",
    "num_layers = 3\n",
    "num_heads = 4\n",
    "learning_rate = 0.001\n",
    "num_epochs = 100\n",
    "batch_size = 32  # If you're using full-batch training, this will be ignored\n",
    "\n",
    "# Determine the number of classes for genes and variants\n",
    "num_gene_classes = len(torch.unique(data['gene'].y))\n",
    "num_variant_classes = len(torch.unique(data['variant'].y))\n",
    "\n",
    "print(f\"Number of gene classes: {num_gene_classes}\")\n",
    "print(f\"Number of variant classes: {num_variant_classes}\")\n",
    "\n",
    "# Create the model with the correct number of output classes\n",
    "model = GraphSAGEWithAttention(hidden_channels, out_channels, num_layers, num_heads, num_gene_classes, num_variant_classes)\n",
    "\n",
    "# ... (train_val_split, train_epoch, validate, and train_and_validate functions remain the same)\n",
    "\n",
    "# Split the data into train and validation sets\n",
    "data = train_val_split(data)\n",
    "\n",
    "# Set up optimizer and loss function\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Train and validate the model\n",
    "best_model = train_and_validate(model, data, optimizer, criterion, num_epochs)\n",
    "\n",
    "# Load the best model\n",
    "model.load_state_dict(best_model)\n",
    "\n",
    "print(\"Training and validation completed. The model with the best validation loss has been saved.\")\n",
    "\n",
    "# For inference on new data\n",
    "def inference(model, new_data):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        out = model(new_data.x_dict, new_data.edge_index_dict)\n",
    "    return out\n",
    "\n",
    "# Example of using the trained model for inference\n",
    "# new_data = ... # Prepare your new data\n",
    "# predictions = inference(model, new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "1aa7837b-4599-49b4-a7ae-2a6d130d0883",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(model, data):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Forward pass through all layers except the final classification\n",
    "        x_dict = data.x_dict\n",
    "        edge_index_dict = data.edge_index_dict\n",
    "        \n",
    "        # Get embeddings before final classification layer\n",
    "        for conv, attention in zip(model.convs, model.attentions):\n",
    "            x_dict = conv(x_dict, edge_index_dict)\n",
    "            x_dict = {key: attention(F.relu(x)) for key, x in x_dict.items()}\n",
    "        \n",
    "        # Return embeddings for both node types\n",
    "        return {\n",
    "            'gene_embeddings': x_dict['gene'].cpu().numpy(),\n",
    "            'variant_embeddings': x_dict['variant'].cpu().numpy()\n",
    "        }\n",
    "\n",
    "# Usage example:\n",
    "embeddings = get_embeddings(model, data)\n",
    "variant_embeddings = embeddings['variant_embeddings']\n",
    "gene_embeddings = embeddings['gene_embeddings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "5661655a-ff0c-46e3-b7b9-526e7f5ae7b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(328116, 64)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variant_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ad905a8f-addc-4f11-a481-79dd7d259942",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(136, 64)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gene_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "7d6270f2-51a8-494c-8966-4c61b3d56ade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "328116"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(merged_df[\"bin_class\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "65b4567a-19c5-438c-b374-08ac42b4820a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>190999</th>\n",
       "      <td>-0.153794</td>\n",
       "      <td>-0.072410</td>\n",
       "      <td>-0.154319</td>\n",
       "      <td>0.053987</td>\n",
       "      <td>-0.076169</td>\n",
       "      <td>0.157506</td>\n",
       "      <td>-0.256178</td>\n",
       "      <td>0.025342</td>\n",
       "      <td>0.051852</td>\n",
       "      <td>0.061117</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.074244</td>\n",
       "      <td>-0.002142</td>\n",
       "      <td>0.070283</td>\n",
       "      <td>0.102546</td>\n",
       "      <td>0.120940</td>\n",
       "      <td>-0.135901</td>\n",
       "      <td>0.085995</td>\n",
       "      <td>0.070193</td>\n",
       "      <td>-0.006450</td>\n",
       "      <td>0.076242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9316</th>\n",
       "      <td>-0.149907</td>\n",
       "      <td>-0.032813</td>\n",
       "      <td>-0.144135</td>\n",
       "      <td>0.029721</td>\n",
       "      <td>-0.026771</td>\n",
       "      <td>0.130631</td>\n",
       "      <td>-0.224828</td>\n",
       "      <td>0.003251</td>\n",
       "      <td>0.011762</td>\n",
       "      <td>0.071105</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.051207</td>\n",
       "      <td>0.000336</td>\n",
       "      <td>0.044873</td>\n",
       "      <td>0.083529</td>\n",
       "      <td>0.109780</td>\n",
       "      <td>-0.105402</td>\n",
       "      <td>0.080260</td>\n",
       "      <td>0.040757</td>\n",
       "      <td>-0.010369</td>\n",
       "      <td>0.044516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311117</th>\n",
       "      <td>-0.147024</td>\n",
       "      <td>-0.053525</td>\n",
       "      <td>-0.152767</td>\n",
       "      <td>0.041993</td>\n",
       "      <td>-0.056459</td>\n",
       "      <td>0.145730</td>\n",
       "      <td>-0.241319</td>\n",
       "      <td>0.011592</td>\n",
       "      <td>0.047815</td>\n",
       "      <td>0.073964</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.052115</td>\n",
       "      <td>-0.011020</td>\n",
       "      <td>0.059478</td>\n",
       "      <td>0.089930</td>\n",
       "      <td>0.105859</td>\n",
       "      <td>-0.114956</td>\n",
       "      <td>0.086431</td>\n",
       "      <td>0.053374</td>\n",
       "      <td>-0.016799</td>\n",
       "      <td>0.061094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162094</th>\n",
       "      <td>-0.159829</td>\n",
       "      <td>-0.005003</td>\n",
       "      <td>-0.149625</td>\n",
       "      <td>-0.002459</td>\n",
       "      <td>-0.008023</td>\n",
       "      <td>0.098057</td>\n",
       "      <td>-0.186727</td>\n",
       "      <td>-0.000990</td>\n",
       "      <td>-0.041893</td>\n",
       "      <td>0.068145</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.032314</td>\n",
       "      <td>0.027028</td>\n",
       "      <td>0.019509</td>\n",
       "      <td>0.078667</td>\n",
       "      <td>0.113544</td>\n",
       "      <td>-0.086500</td>\n",
       "      <td>0.077419</td>\n",
       "      <td>0.017319</td>\n",
       "      <td>-0.002429</td>\n",
       "      <td>0.017316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193635</th>\n",
       "      <td>-0.147419</td>\n",
       "      <td>-0.043751</td>\n",
       "      <td>-0.143085</td>\n",
       "      <td>0.034372</td>\n",
       "      <td>-0.039239</td>\n",
       "      <td>0.138817</td>\n",
       "      <td>-0.231912</td>\n",
       "      <td>0.007814</td>\n",
       "      <td>0.021180</td>\n",
       "      <td>0.070984</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.056368</td>\n",
       "      <td>-0.005829</td>\n",
       "      <td>0.051130</td>\n",
       "      <td>0.086065</td>\n",
       "      <td>0.109628</td>\n",
       "      <td>-0.111940</td>\n",
       "      <td>0.079973</td>\n",
       "      <td>0.046068</td>\n",
       "      <td>-0.012105</td>\n",
       "      <td>0.049984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38623</th>\n",
       "      <td>-0.170107</td>\n",
       "      <td>-0.052981</td>\n",
       "      <td>-0.162956</td>\n",
       "      <td>0.035983</td>\n",
       "      <td>-0.058032</td>\n",
       "      <td>0.147965</td>\n",
       "      <td>-0.246658</td>\n",
       "      <td>0.016369</td>\n",
       "      <td>0.053838</td>\n",
       "      <td>0.071614</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.044569</td>\n",
       "      <td>0.004916</td>\n",
       "      <td>0.069907</td>\n",
       "      <td>0.091749</td>\n",
       "      <td>0.110279</td>\n",
       "      <td>-0.108404</td>\n",
       "      <td>0.108771</td>\n",
       "      <td>0.062611</td>\n",
       "      <td>-0.007980</td>\n",
       "      <td>0.073637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216257</th>\n",
       "      <td>-0.149908</td>\n",
       "      <td>-0.037703</td>\n",
       "      <td>-0.144551</td>\n",
       "      <td>0.032327</td>\n",
       "      <td>-0.032586</td>\n",
       "      <td>0.134486</td>\n",
       "      <td>-0.228701</td>\n",
       "      <td>0.005707</td>\n",
       "      <td>0.016299</td>\n",
       "      <td>0.070751</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.053798</td>\n",
       "      <td>-0.001161</td>\n",
       "      <td>0.047953</td>\n",
       "      <td>0.085307</td>\n",
       "      <td>0.110538</td>\n",
       "      <td>-0.108868</td>\n",
       "      <td>0.080694</td>\n",
       "      <td>0.043548</td>\n",
       "      <td>-0.010668</td>\n",
       "      <td>0.047456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236682</th>\n",
       "      <td>-0.150062</td>\n",
       "      <td>-0.036251</td>\n",
       "      <td>-0.144542</td>\n",
       "      <td>0.031689</td>\n",
       "      <td>-0.030867</td>\n",
       "      <td>0.133352</td>\n",
       "      <td>-0.227642</td>\n",
       "      <td>0.005080</td>\n",
       "      <td>0.014993</td>\n",
       "      <td>0.070806</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.053104</td>\n",
       "      <td>-0.000501</td>\n",
       "      <td>0.047083</td>\n",
       "      <td>0.084882</td>\n",
       "      <td>0.110418</td>\n",
       "      <td>-0.107922</td>\n",
       "      <td>0.080662</td>\n",
       "      <td>0.042770</td>\n",
       "      <td>-0.010509</td>\n",
       "      <td>0.046665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161348</th>\n",
       "      <td>-0.146522</td>\n",
       "      <td>-0.054566</td>\n",
       "      <td>-0.152734</td>\n",
       "      <td>0.042997</td>\n",
       "      <td>-0.057826</td>\n",
       "      <td>0.146412</td>\n",
       "      <td>-0.241986</td>\n",
       "      <td>0.012489</td>\n",
       "      <td>0.048261</td>\n",
       "      <td>0.073482</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.053486</td>\n",
       "      <td>-0.011270</td>\n",
       "      <td>0.059461</td>\n",
       "      <td>0.090455</td>\n",
       "      <td>0.106339</td>\n",
       "      <td>-0.116443</td>\n",
       "      <td>0.085655</td>\n",
       "      <td>0.053974</td>\n",
       "      <td>-0.016590</td>\n",
       "      <td>0.061834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184632</th>\n",
       "      <td>-0.158558</td>\n",
       "      <td>-0.025259</td>\n",
       "      <td>-0.150358</td>\n",
       "      <td>0.022016</td>\n",
       "      <td>-0.025459</td>\n",
       "      <td>0.122508</td>\n",
       "      <td>-0.214250</td>\n",
       "      <td>0.004879</td>\n",
       "      <td>-0.007648</td>\n",
       "      <td>0.065384</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.049488</td>\n",
       "      <td>0.015008</td>\n",
       "      <td>0.037835</td>\n",
       "      <td>0.085693</td>\n",
       "      <td>0.115790</td>\n",
       "      <td>-0.103531</td>\n",
       "      <td>0.080320</td>\n",
       "      <td>0.036702</td>\n",
       "      <td>-0.004871</td>\n",
       "      <td>0.035762</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6   \\\n",
       "190999 -0.153794 -0.072410 -0.154319  0.053987 -0.076169  0.157506 -0.256178   \n",
       "9316   -0.149907 -0.032813 -0.144135  0.029721 -0.026771  0.130631 -0.224828   \n",
       "311117 -0.147024 -0.053525 -0.152767  0.041993 -0.056459  0.145730 -0.241319   \n",
       "162094 -0.159829 -0.005003 -0.149625 -0.002459 -0.008023  0.098057 -0.186727   \n",
       "193635 -0.147419 -0.043751 -0.143085  0.034372 -0.039239  0.138817 -0.231912   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "38623  -0.170107 -0.052981 -0.162956  0.035983 -0.058032  0.147965 -0.246658   \n",
       "216257 -0.149908 -0.037703 -0.144551  0.032327 -0.032586  0.134486 -0.228701   \n",
       "236682 -0.150062 -0.036251 -0.144542  0.031689 -0.030867  0.133352 -0.227642   \n",
       "161348 -0.146522 -0.054566 -0.152734  0.042997 -0.057826  0.146412 -0.241986   \n",
       "184632 -0.158558 -0.025259 -0.150358  0.022016 -0.025459  0.122508 -0.214250   \n",
       "\n",
       "              7         8         9   ...        54        55        56  \\\n",
       "190999  0.025342  0.051852  0.061117  ... -0.074244 -0.002142  0.070283   \n",
       "9316    0.003251  0.011762  0.071105  ... -0.051207  0.000336  0.044873   \n",
       "311117  0.011592  0.047815  0.073964  ... -0.052115 -0.011020  0.059478   \n",
       "162094 -0.000990 -0.041893  0.068145  ... -0.032314  0.027028  0.019509   \n",
       "193635  0.007814  0.021180  0.070984  ... -0.056368 -0.005829  0.051130   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "38623   0.016369  0.053838  0.071614  ... -0.044569  0.004916  0.069907   \n",
       "216257  0.005707  0.016299  0.070751  ... -0.053798 -0.001161  0.047953   \n",
       "236682  0.005080  0.014993  0.070806  ... -0.053104 -0.000501  0.047083   \n",
       "161348  0.012489  0.048261  0.073482  ... -0.053486 -0.011270  0.059461   \n",
       "184632  0.004879 -0.007648  0.065384  ... -0.049488  0.015008  0.037835   \n",
       "\n",
       "              57        58        59        60        61        62        63  \n",
       "190999  0.102546  0.120940 -0.135901  0.085995  0.070193 -0.006450  0.076242  \n",
       "9316    0.083529  0.109780 -0.105402  0.080260  0.040757 -0.010369  0.044516  \n",
       "311117  0.089930  0.105859 -0.114956  0.086431  0.053374 -0.016799  0.061094  \n",
       "162094  0.078667  0.113544 -0.086500  0.077419  0.017319 -0.002429  0.017316  \n",
       "193635  0.086065  0.109628 -0.111940  0.079973  0.046068 -0.012105  0.049984  \n",
       "...          ...       ...       ...       ...       ...       ...       ...  \n",
       "38623   0.091749  0.110279 -0.108404  0.108771  0.062611 -0.007980  0.073637  \n",
       "216257  0.085307  0.110538 -0.108868  0.080694  0.043548 -0.010668  0.047456  \n",
       "236682  0.084882  0.110418 -0.107922  0.080662  0.042770 -0.010509  0.046665  \n",
       "161348  0.090455  0.106339 -0.116443  0.085655  0.053974 -0.016590  0.061834  \n",
       "184632  0.085693  0.115790 -0.103531  0.080320  0.036702 -0.004871  0.035762  \n",
       "\n",
       "[1000 rows x 64 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = pd.DataFrame(variant_embeddings)\n",
    "temp = temp.sample(n=1000, random_state=2024)\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "60fe0ccd-131f-4109-8f93-1cf1035d2a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "standard_embedding = umap.UMAP().fit_transform(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "ac4e6324-3619-4bc9-97f2-d2ecf66dc02d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(standard_embedding[:, 0], standard_embedding[:, 1], s=0.5);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
