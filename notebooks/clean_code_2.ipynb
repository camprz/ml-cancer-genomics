{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67b8ea2-7d0c-49eb-a599-57e10a88061d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from category_encoders import BinaryEncoder\n",
    "\n",
    "# Group by gene and kind, and then aggregate\n",
    "upgenevsrep[\"position\"] = upgenevsrep[\"position\"].astype(float)\n",
    "# Group by gene and kind, and then aggregate\n",
    "grouped_df = upgenevsrep.groupby(['gene', 'kind']).agg(\n",
    "    mean_position=('position', 'mean'),\n",
    "    var_position=('position', 'var'),\n",
    "    counts=('counts', 'sum'),\n",
    ").reset_index()\n",
    "\n",
    "grouped_df[\"var_position\"] = grouped_df[\"var_position\"].fillna(0.0).round(2)\n",
    "grouped_df[\"mean_position\"] = grouped_df[\"mean_position\"].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f40124f-354e-41e6-b43f-6d09f3e0c999",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantile_transformer = QuantileTransformer(output_distribution='normal', n_quantiles=400, random_state=0)\n",
    "oe_transformer = OrdinalEncoder()\n",
    "be_transformer = BinaryEncoder()\n",
    "\n",
    "mean_quantile_transf = quantile_transformer.fit_transform(grouped_df[\"mean_position\"].values.reshape(-1, 1))\n",
    "var_quantile_transf = quantile_transformer.fit_transform(grouped_df[\"var_position\"].values.reshape(-1, 1))\n",
    "count_quantile_transf = quantile_transformer.fit_transform(grouped_df[\"counts\"].values.reshape(-1, 1))\n",
    "\n",
    "gene_transf = be_transformer.fit_transform(grouped_df[\"gene\"].values.reshape(-1, 1))\n",
    "gene_transf.columns = [\"gene_1\", \"gene_2\", \"gene_3\", \"gene_4\", \"gene_5\", \"gene_6\", \"gene_7\", \"gene_8\"]\n",
    "kind_transf = be_transformer.fit_transform(grouped_df[\"kind\"].values.reshape(-1, 1))\n",
    "kind_transf.columns = [\"kind_1\", \"kind_2\", \"kind_3\"]\n",
    "\n",
    "grouped_df[\"transf_mean\"] = mean_quantile_transf\n",
    "grouped_df[\"transf_var\"] = var_quantile_transf\n",
    "grouped_df[\"transf_count\"] = count_quantile_transf\n",
    "grouped_df = pd.concat([grouped_df, \n",
    "                        gene_transf, \n",
    "                        kind_transf], axis=1)\n",
    "\n",
    "sns.scatterplot(data=grouped_df, x=\"transf_mean\", y=\"transf_var\", hue=\"kind\")\n",
    "plt.title(\"Mean and Variance Position\")\n",
    "plt.xlabel(\"Mean Position\")\n",
    "plt.ylabel(\"Variance Position\")\n",
    "plt.show();\n",
    "\n",
    "sns.scatterplot(data=grouped_df, x=\"transf_mean\", y=\"transf_count\", hue=\"kind\")\n",
    "plt.title(\"Mean Position vs Counts\")\n",
    "plt.xlabel(\"Mean Position\")\n",
    "plt.ylabel(\"Counts\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0a79d4-daac-4168-b475-6fe2930d56c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "import joblib\n",
    "\n",
    "umap_df = grouped_df[[ 'transf_var', 'transf_count', 'transf_mean', \n",
    "                      'gene_1', 'gene_2', 'gene_3', 'gene_4', 'gene_5', 'gene_6', 'gene_7', 'gene_8', \n",
    "                      'kind_1', 'kind_2', 'kind_3']].copy()\n",
    "\n",
    "for i in [25, 26, 27]:\n",
    "\n",
    "    model = umap.UMAP(n_neighbors=i,\n",
    "                     min_dist=0.0,\n",
    "                     n_components=3).fit(umap_df)\n",
    "\n",
    "    clusterable_embedding = model.transform(umap_df)    \n",
    "\n",
    "    # save the model to disk\n",
    "    filename = f'./models/trained_models/upgene_umap_n_neighbor_{i}.sav'\n",
    "    joblib.dump(model, filename)\n",
    "\n",
    "    labels = HDBSCAN(min_samples=10,\n",
    "                     min_cluster_size=20,\n",
    "                     ).fit_predict(clusterable_embedding)\n",
    "    \n",
    "    ncluster = len(np.unique(labels))\n",
    "    score = round(silhouette_score(umap_df, labels),6)\n",
    "    # save the model to disk\n",
    "    filename = f'./models/trained_models/upgene_hdbscan_umap_{i}.sav'\n",
    "    joblib.dump(model, filename)\n",
    "    \n",
    "    fig = plt.figure(figsize=(10, 6), dpi=300)\n",
    "\n",
    "    # Plot UMAP in 3D\n",
    "    ax2 = fig.add_subplot(122, projection='3d')\n",
    "    ax2.scatter(clusterable_embedding[:, 0], clusterable_embedding[:, 1], clusterable_embedding[:, 2], s=5)\n",
    "    ax2.set_xlabel('')\n",
    "    ax2.set_ylabel('')\n",
    "    ax2.set_zlabel('')\n",
    "    # Plot UMAP in 3D\n",
    "    ax1 = fig.add_subplot(121, projection='3d')\n",
    "    ax1.scatter(clusterable_embedding[:, 0], clusterable_embedding[:, 1], clusterable_embedding[:, 2], s=5, c=labels)\n",
    "    ax1.set_xlabel('')\n",
    "    ax1.set_ylabel('')\n",
    "    ax1.set_zlabel('')\n",
    "\n",
    "    plt.suptitle(f'UMAP n_neighbors={i}, ncluster={ncluster}, sil. score {score}')\n",
    "    plt.savefig(f\"./results/figures/upgenvsrep_umap_{i}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b44974d-bf85-4c4a-8f50-22fdd7049d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    " # load the model from disk\n",
    "filename = f'./models/trained_models/upgene_umap_n_neighbor_26.sav'\n",
    "loaded_model = joblib.load(filename)\n",
    "result = loaded_model.transform(umap_df)\n",
    "\n",
    "labels = HDBSCAN(min_samples=10,\n",
    "                     min_cluster_size=20,\n",
    "                     ).fit_predict(result)\n",
    "    \n",
    "ncluster = len(np.unique(labels))\n",
    "score = round(silhouette_score(result, labels),6)\n",
    "\n",
    "grouped_df[\"labels\"] = labels\n",
    "percentages = grouped_df.groupby(['labels', 'gene']).agg(\n",
    "    counts=('gene', 'size'),\n",
    "    agg_kind=('kind', lambda x: ', '.join(sorted(x.unique())))\n",
    ").reset_index()\n",
    "percentages[\"perc\"] = round((percentages[\"counts\"]/sum(percentages[\"counts\"]))*100, 2)\n",
    "percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ddc367-4b49-492c-8085-19e19696ee2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import silhouette_score\n",
    "import umap\n",
    "from scipy.stats import sem\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Parameters\n",
    "n_neighbors_list = [5, 10, 12, 13, 14, 15, 16, 20, 22, 25, 26]\n",
    "n_trials = 50\n",
    "\n",
    "# Initialize dictionary to store results\n",
    "results = {n: [] for n in n_neighbors_list}\n",
    "\n",
    "# Main loop with progress bar\n",
    "for i in tqdm(n_neighbors_list, desc='n_neighbors'):\n",
    "    for _ in range(n_trials), desc=f'Trials for n_neighbors={i}', leave=False):\n",
    "        # Perform UMAP\n",
    "        clusterable_embedding = umap.UMAP(\n",
    "                                n_neighbors=i,\n",
    "                                min_dist=0.0,\n",
    "                                n_components=3).fit_transform(umap_df)\n",
    "\n",
    "        # Perform HDBSCAN\n",
    "        labels = HDBSCAN(min_samples=10,\n",
    "                                 min_cluster_size=20,\n",
    "                                 ).fit_predict(clusterable_embedding)\n",
    "\n",
    "        # Calculate the number of clusters\n",
    "        ncluster = len(np.unique(labels))\n",
    "\n",
    "        # Calculate silhouette score\n",
    "        if ncluster > 1:\n",
    "            score = round(silhouette_score(umap_df, labels), 3)\n",
    "        else:\n",
    "            score = -1  # Assign a default bad score if there's only one cluster\n",
    "\n",
    "        # Store the score\n",
    "        results[i].append(score)\n",
    "\n",
    "# Calculate statistics\n",
    "stats = {\n",
    "    'n_neighbors': [],\n",
    "    'mean_score': [],\n",
    "    'variance_score': [],\n",
    "    'sem_score': []  # Standard Error of the Mean\n",
    "}\n",
    "\n",
    "for n in n_neighbors_list:\n",
    "    scores = results[n]\n",
    "    stats['n_neighbors'].append(n)\n",
    "    stats['mean_score'].append(np.mean(scores))\n",
    "    stats['variance_score'].append(np.var(scores))\n",
    "    stats['sem_score'].append(sem(scores))\n",
    "\n",
    "# Convert to DataFrame\n",
    "stats_df = pd.DataFrame(stats)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.errorbar(stats_df['n_neighbors'], stats_df['mean_score'], yerr=stats_df['sem_score'], fmt='-o')\n",
    "plt.xlabel('n_neighbors')\n",
    "plt.ylabel('Mean Silhouette Score')\n",
    "plt.title('Mean Silhouette Score vs. n_neighbors with Confidence Interval')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Print DataFrame\n",
    "print(stats_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genomics_env",
   "language": "python",
   "name": "genomics_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
